{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Jupyter configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import keras\n",
    "import keras.backend as K\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import preprocessing as pp\n",
    "import sys, inspect, argparse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accuracy Metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# percentage of samples that exactly match\n",
    "def exact_match_accuracy(y_true, y_pred):\n",
    "    argmax_true = tf.math.argmax(y_true, axis=2)            # onehot to index               (batch, width, onehot:int) -> (batch, width:int)\n",
    "    argmax_pred = tf.math.argmax(y_pred, axis=2)            # onehot to index               (batch, width, onehot:int) -> (batch, width:int)\n",
    "    match_char = tf.math.equal(argmax_true, argmax_pred)    # match characters              (batch, width:int) -> (batch, width:bool)\n",
    "    match_word = tf.math.reduce_all(match_char, axis=1)     # require all character in sample to match      (batch, width:bool) -> (batch:bool)\n",
    "    match_int = tf.cast(match_word, tf.float32)             # bool to int                                   (batch:bool) -> (batch:int)\n",
    "    return tf.reduce_mean(match_int)                        # percentage of samples that are an exact match (batch:int) -> int"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Log function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "verbose = False\n",
    "def log(*l, **d): \n",
    "    if verbose: print(*l, **d)\n",
    "        \n",
    "training_history = []\n",
    "\n",
    "def training_log(x, y, a, b, e, l, m):\n",
    "    training_history.append({'x':x, 'y':y, 'architecture':a, 'batch size':b, 'epochs':e, 'loss':l, 'accuracy':m})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_size = 15\n",
    "architecture = ''\n",
    "\n",
    "metrics = ['mean_absolute_error', 'categorical_accuracy', 'binary_accuracy', exact_match_accuracy]\n",
    "loss = 'mean_squared_logarithmic_error' # poisson mean_squared_logarithmic_error categorical_crossentropy\n",
    "\n",
    "models = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pp.load('training_data.p')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_x\t(19123, 182, 79)\ttrain_y\t(19123, 12, 79)\ttest_x\t(4780, 182, 79)\ttest_y\t(4780, 12, 79)\tshowcase_x\t(23, 182, 79)\tshowcase_y\t(23, 12, 79)\n"
     ]
    }
   ],
   "source": [
    "subset = slice(None) # only use subset of the dataset\n",
    "x_cut = (subset, slice(None))\n",
    "y_cut = (subset, slice(0,12))\n",
    "\n",
    "x_name, y_name = 'LookupDOSFilePath', 'LookupDOSFilePath'\n",
    "shuffle_before, shuffle_after = False, True\n",
    "test_split_frac, showcase_split_frac = 0.2, 0.005\n",
    "\n",
    "\n",
    "# spli data into x and y as well as training and test set\n",
    "(train_x, train_y), (test_x, test_y) = pp.train_test_split(data[x_name][subset], data[y_name][subset], test_frac=test_split_frac, shuffle_before=shuffle_before, shuffle_after=shuffle_after) # split training and test\n",
    "(_, _), (showcase_x, showcase_y) = pp.train_test_split(test_x, test_y, test_frac=showcase_split_frac, shuffle_before=True, shuffle_after=False) # extract small showcase subset of test\n",
    "\n",
    "log('train_x', train_x.shape, 'train_y', train_y.shape, test_y.shape, sep='\\t')\n",
    "\n",
    "voc_size = pp.char_count\n",
    "\n",
    "# original size\n",
    "x_org_shape = [*train_x.shape]\n",
    "x_org_shape[0] = None\n",
    "y_org_shape = [*train_y.shape]\n",
    "y_org_shape[0] = None\n",
    "\n",
    "# one hot encode output because the model cant do that for some reason\n",
    "train_x = train_x[x_cut]\n",
    "test_x = test_x[x_cut]\n",
    "showcase_x = showcase_x[x_cut]\n",
    "train_y = train_y[y_cut]\n",
    "test_y = test_y[y_cut]\n",
    "showcase_y = showcase_y[y_cut]\n",
    "\n",
    "# output to onehot categorical encoding\n",
    "train_x = keras.utils.to_categorical(train_x, voc_size)\n",
    "test_x = keras.utils.to_categorical(test_x, voc_size)\n",
    "showcase_x = keras.utils.to_categorical(showcase_x, voc_size)\n",
    "train_y = keras.utils.to_categorical(train_y, voc_size)\n",
    "test_y = keras.utils.to_categorical(test_y, voc_size)\n",
    "showcase_y = keras.utils.to_categorical(showcase_y, voc_size)\n",
    "\n",
    "# store input and output shape\n",
    "x_shape = [*train_x.shape]\n",
    "x_shape[0] = None\n",
    "y_shape = [*train_y.shape]\n",
    "y_shape[0] = None\n",
    "\n",
    "# named shape attributes\n",
    "x_shape_char, x_shape_ones, *_ = x_shape[1:] + [None]\n",
    "y_shape_char, y_shape_ones, *_ = y_shape[1:] + [None]\n",
    "\n",
    "print('train_x', train_x.shape, 'train_y', train_y.shape, 'test_x', test_x.shape, 'test_y', test_y.shape, 'showcase_x', showcase_x.shape, 'showcase_y', showcase_y.shape, sep='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test and show samlpe output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test():\n",
    "    p_one_hot = model.predict(showcase_x)\n",
    "    p_vector = np.argmax(p_one_hot, 2)\n",
    "    p_strings = pp.decode_data(p_vector)\n",
    "\n",
    "    y_vector = np.argmax(showcase_y, 2)\n",
    "    y_strings = pp.decode_data(y_vector)\n",
    "\n",
    "    #x_vector = np.argmax(showcase_x, 2)\n",
    "    x_strings = pp.decode_data(showcase_x)\n",
    "\n",
    "    x_strings = [s.replace('<Padding>', '') for s in x_strings]\n",
    "    y_strings = [s.replace('<Padding>', '') for s in y_strings]\n",
    "    p_strings = [s.replace('<Padding>', '') for s in p_strings]\n",
    "    x_w, y_w, p_w = max([len(s) for s in x_strings]), max([len(s) for s in y_strings]), max([len(s) for s in p_strings])\n",
    "    y_p_strings = ['  '.join([x.ljust(x_w), y.ljust(y_w), p.ljust(p_w), str(y==p)]) for x, y, p in zip(x_strings, y_strings, p_strings)]\n",
    "\n",
    "    print(*y_p_strings, sep='\\n', end='\\n\\n')\n",
    "\n",
    "    # accuracy on entire training set\n",
    "    accuracies = model.evaluate(test_x, test_y)\n",
    "    print(*list(zip([loss]+metrics, accuracies)), sep='\\n', end='\\n\\n') # evaluate and list loss and each metric\n",
    "    \n",
    "    return accuracies[0], accuracies[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Character Encoder-Decoder: Input, Hidden, Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lh (Dense)                   (None, 15)                1200      \n",
      "_________________________________________________________________\n",
      "lo (Dense)                   (None, 79)                1264      \n",
      "=================================================================\n",
      "Total params: 2,464\n",
      "Trainable params: 2,464\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "architecture = 'E-D-NN'\n",
    "\n",
    "model_E_D_NN = keras.Sequential()\n",
    "model_E_D_NN.add(keras.layers.Dense(embedding_size, activation='exponential', name='lh', input_shape=(voc_size,)))           # dense layer\n",
    "model_E_D_NN.add(keras.layers.Dense(voc_size, activation='exponential', name='lo'))           # dense layer\n",
    "#model_E_D_NN.add(keras.layers.Dropout(0.001))                                                                  # dropout to prevent overfitting\n",
    "model_E_D_NN.compile(optimizer='adam', loss=loss, metrics=['accuracy', 'mean_absolute_error', 'categorical_accuracy', 'binary_accuracy'])\n",
    "models[architecture] = model_E_D_NN\n",
    "print(model_E_D_NN.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Encoder and Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "3480386/3480386 [==============================] - 124s 36us/step - loss: 4.7579e-07 - acc: 1.0000 - mean_absolute_error: 1.2808e-04 - categorical_accuracy: 1.0000 - binary_accuracy: 1.0000\n",
      "Epoch 2/5\n",
      "3480386/3480386 [==============================] - 109s 31us/step - loss: 4.6655e-07 - acc: 1.0000 - mean_absolute_error: 1.1237e-04 - categorical_accuracy: 1.0000 - binary_accuracy: 1.0000\n",
      "Epoch 3/5\n",
      " 610816/3480386 [====>.........................] - ETA: 1:19 - loss: 4.3738e-07 - acc: 1.0000 - mean_absolute_error: 1.0983e-04 - categorical_accuracy: 1.0000 - binary_accuracy: 1.0000"
     ]
    }
   ],
   "source": [
    "epochs = 5\n",
    "batch_size = 128\n",
    "model = models['E-D-NN']\n",
    "\n",
    "model.fit(train_x.reshape(-1, voc_size), train_x.reshape(-1, voc_size), batch_size=batch_size, epochs=epochs)\n",
    "model.evaluate(test_x.reshape(-1, voc_size), test_x.reshape(-1, voc_size))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### P-NN: Input, Embedding, Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "le (Embedding)               (None, 23, 20)            1580      \n",
      "_________________________________________________________________\n",
      "flatten_11 (Flatten)         (None, 460)               0         \n",
      "_________________________________________________________________\n",
      "lo (Dense)                   (None, 948)               437028    \n",
      "_________________________________________________________________\n",
      "dropout_14 (Dropout)         (None, 948)               0         \n",
      "_________________________________________________________________\n",
      "reshape_26 (Reshape)         (None, 12, 79)            0         \n",
      "=================================================================\n",
      "Total params: 438,608\n",
      "Trainable params: 438,608\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "architecture = 'P-NN'\n",
    "\n",
    "model_P_NN = keras.Sequential()\n",
    "model_P_NN.add(keras.layers.Embedding(y_shape_ones, embedding_size, name='le', input_length=x_shape_char))   # embed characters into dense embedded space\n",
    "model_P_NN.add(keras.layers.Flatten())                                                                       # flatten to 1D per sample\n",
    "model_P_NN.add(keras.layers.Dense(y_shape_char*y_shape_ones, activation='exponential', name='lo'))           # dense layer\n",
    "model_P_NN.add(keras.layers.Dropout(0.001))                                                                  # dropout to prevent overfitting\n",
    "model_P_NN.add(keras.layers.Reshape((y_shape_char, y_shape_ones)))                                           # un flatten\n",
    "model_P_NN.compile(optimizer='adam', loss=loss, metrics=metrics)\n",
    "models[architecture] = model_P_NN\n",
    "print(model_P_NN.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FF-NN: Input, Embedding, Hidden, Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "le (Embedding)               (None, 23, 20)            1580      \n",
      "_________________________________________________________________\n",
      "flatten_5 (Flatten)          (None, 460)               0         \n",
      "_________________________________________________________________\n",
      "lh (Dense)                   (None, 1264)              582704    \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 1264)              0         \n",
      "_________________________________________________________________\n",
      "lo (Dense)                   (None, 948)               1199220   \n",
      "_________________________________________________________________\n",
      "reshape_7 (Reshape)          (None, 12, 79)            0         \n",
      "=================================================================\n",
      "Total params: 1,783,504\n",
      "Trainable params: 1,783,504\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "architecture = 'FF-NN'\n",
    "hidden_size = (y_shape_ones*embedding_size + y_shape_char*y_shape_ones) // 2\n",
    "\n",
    "model_FF_NN = keras.Sequential()\n",
    "model_FF_NN.add(keras.layers.Embedding(y_shape_ones, embedding_size, name='le', input_length=x_shape_char))   # embed characters into dense embedded space\n",
    "model_FF_NN.add(keras.layers.Flatten())                                                                       # flatten to 1D per sample\n",
    "model_FF_NN.add(keras.layers.Dense(hidden_size, activation='exponential', name='lh'))                         # dense layer\n",
    "model_FF_NN.add(keras.layers.Dropout(0.2))                                                                    # dropout to prevent overfitting\n",
    "model_FF_NN.add(keras.layers.Dense(y_shape_char*y_shape_ones, activation='exponential', name='lo'))           # dense layer\n",
    "model_FF_NN.add(keras.layers.Reshape((y_shape_char, y_shape_ones)))                                           # un flatten\n",
    "model_FF_NN.compile(optimizer='adam', loss=loss, metrics=metrics)\n",
    "models[architecture] = model_FF_NN\n",
    "print(model_FF_NN.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTM-RNN1: Input, Embedding, (LSTM), Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "le (Embedding)               (None, 23, 20)            1580      \n",
      "_________________________________________________________________\n",
      "lstm_7 (LSTM)                (None, 948)               3674448   \n",
      "_________________________________________________________________\n",
      "reshape_15 (Reshape)         (None, 12, 79)            0         \n",
      "=================================================================\n",
      "Total params: 3,676,028\n",
      "Trainable params: 3,676,028\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "architecture = 'LSTM-RNN1'\n",
    "lstm_hidden_size = embedding_size * 15\n",
    "\n",
    "model_LSTM_RNN1 = keras.Sequential()\n",
    "model_LSTM_RNN1.add(keras.layers.Embedding(y_shape_ones, embedding_size, name='le', input_length=x_shape_char))   # embed characters into dense embedded space\n",
    "#model_LSTM_RNN1.add(keras.layers.Dropout(0.2))                                                                    # dropout to prevent overfitting\n",
    "model_LSTM_RNN1.add(keras.activation.exponential())\n",
    "model_LSTM_RNN1.add(keras.layers.LSTM(y_shape_char * y_shape_ones, activation='exponential', implementation=2, unroll=True))                # lstm recurrent cell\n",
    "model_LSTM_RNN1.add(keras.layers.Reshape((y_shape_char, y_shape_ones)))                                           # un flatten\n",
    "model_LSTM_RNN1.compile(optimizer='adam', loss=loss, metrics=metrics)\n",
    "models[architecture] = model_LSTM_RNN1\n",
    "print(model_LSTM_RNN1.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTM-RNN2: Input, Embedding, (LSTM), Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "All layers in a Sequential model should have a single output tensor. For multi-output layers, use the functional API.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-18-b75df2613e99>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mEmbedding\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_shape_ones\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0membedding_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'le'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_length\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mx_shape_char\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m   \u001b[1;31m# embed characters into dense embedded space\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDropout\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0.2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m                                                                    \u001b[1;31m# dropout to prevent overfitting\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mLSTM\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlstm_hidden_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreturn_sequences\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreturn_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m                \u001b[1;31m# lstm recurrent cell\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDense\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_shape_char\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0my_shape_ones\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m                                              \u001b[1;31m# dense combine time series into single output\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mReshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_shape_char\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_shape_ones\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m                                           \u001b[1;31m# un flatten\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\program files\\python36\\lib\\site-packages\\keras\\engine\\sequential.py\u001b[0m in \u001b[0;36madd\u001b[1;34m(self, layer)\u001b[0m\n\u001b[0;32m    181\u001b[0m             \u001b[0moutput_tensor\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    182\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput_tensor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 183\u001b[1;33m                 raise TypeError('All layers in a Sequential model '\n\u001b[0m\u001b[0;32m    184\u001b[0m                                 \u001b[1;34m'should have a single output tensor. '\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    185\u001b[0m                                 \u001b[1;34m'For multi-output layers, '\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: All layers in a Sequential model should have a single output tensor. For multi-output layers, use the functional API."
     ]
    }
   ],
   "source": [
    "architecture = 'LSTM-RNN2'\n",
    "lstm_hidden_size = embedding_size * 15\n",
    "\n",
    "model_LSTM_RNN2 = keras.Sequential()\n",
    "model_LSTM_RNN2.add(keras.layers.Embedding(y_shape_ones, embedding_size, name='le', input_length=x_shape_char))   # embed characters into dense embedded space\n",
    "model_LSTM_RNN2.add(keras.layers.Dropout(0.2))                                                                    # dropout to prevent overfitting\n",
    "model_LSTM_RNN2.add(keras.layers.LSTM(lstm_hidden_size, return_sequences=True, return_state=True))                # lstm recurrent cell\n",
    "model_LSTM_RNN2.add(keras.layers.Dropout(0.2))                                                                    # dropout to prevent overfitting\n",
    "model_LSTM_RNN2.add(keras.layers.Dense(y_shape_char * y_shape_ones))                                              # dense combine time series into single output\n",
    "model_LSTM_RNN2.add(keras.layers.Reshape((y_shape_char, y_shape_ones)))                                           # un flatten\n",
    "model_LSTM_RNN2.compile(optimizer='adam', loss=loss, metrics=metrics)\n",
    "models[architecture] = model_LSTM_RNN2\n",
    "print(model_LSTM_RNN2.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GRU-RNN1: Input, Embedding, (GRU), Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "le (Embedding)               (None, 23, 20)            1580      \n",
      "_________________________________________________________________\n",
      "gru_8 (GRU)                  (None, 948)               2755836   \n",
      "_________________________________________________________________\n",
      "reshape_24 (Reshape)         (None, 12, 79)            0         \n",
      "=================================================================\n",
      "Total params: 2,757,416\n",
      "Trainable params: 2,757,416\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "architecture = 'GRU-RNN1'\n",
    "lstm_hidden_size = voc_size * 15\n",
    "\n",
    "model_GRU_RNN1 = keras.Sequential()\n",
    "model_GRU_RNN1.add(keras.layers.Embedding(y_shape_ones, embedding_size, name='le', input_length=x_shape_char))   # embed characters into dense embedded space\n",
    "#model_GRU_RNN1.add(keras.layers.Dropout(0.2))                                                                    # dropout to prevent overfitting\n",
    "model_GRU_RNN1.add(keras.layers.GRU(y_shape_char * y_shape_ones, activation='relu', implementation=2, unroll=True))                # lstm recurrent cell\n",
    "model_GRU_RNN1.add(keras.layers.Reshape((y_shape_char, y_shape_ones)))                                           # un flatten\n",
    "model_GRU_RNN1.compile(optimizer='adam', loss=loss, metrics=metrics)\n",
    "models[architecture] = model_GRU_RNN1\n",
    "print(model_GRU_RNN1.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GRU-RNN2: Imput Embedding, (GRU), Decoder, Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "le (Embedding)               (None, 23, 20)            1580      \n",
      "_________________________________________________________________\n",
      "gru_10 (GRU)                 (None, 240)               187920    \n",
      "_________________________________________________________________\n",
      "lo (Dense)                   (None, 948)               228468    \n",
      "_________________________________________________________________\n",
      "reshape_27 (Reshape)         (None, 12, 79)            0         \n",
      "=================================================================\n",
      "Total params: 417,968\n",
      "Trainable params: 417,968\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "architecture = 'GRU-RNN2'\n",
    "lstm_hidden_size = embedding_size * 15\n",
    "\n",
    "model_GRU_RNN2 = keras.Sequential()\n",
    "model_GRU_RNN2.add(keras.layers.Embedding(y_shape_ones, embedding_size, name='le', input_length=x_shape_char))            # embed characters into dense embedded space\n",
    "#model_GRU_RNN2.add(keras.layers.Dropout(0.2))                                                                            # dropout to prevent overfitting\n",
    "model_GRU_RNN2.add(keras.layers.GRU(lstm_hidden_size, activation='relu', implementation=2, unroll=True))                  # lstm recurrent cell\n",
    "#model_GRU_RNN2.add(keras.layers.Dropout(0.2))                                                                            # dropout to prevent overfitting\n",
    "model_GRU_RNN2.add(keras.layers.Dense(y_shape_char*y_shape_ones, activation='exponential', name='lo'))                    # dense layer, decode/de-embed\n",
    "model_GRU_RNN2.add(keras.layers.Reshape((y_shape_char, y_shape_ones)))                                                    # un flatten\n",
    "model_GRU_RNN2.compile(optimizer='adam', loss=loss, metrics=metrics)\n",
    "models[architecture] = model_GRU_RNN2\n",
    "print(model_GRU_RNN2.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save/Restore weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "DE = models['E-D-NN'].get_weights()\n",
    "#model_GRU_1 = model\n",
    "#model_GRU_2 = model\n",
    "#model_GRU_3 = model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.set_weights(GRU)\n",
    "#model = model_GRU_3\n",
    "models['E-D-NN'].set_weights(DE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run and Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "19123/19123 [==============================] - 106s 6ms/step - loss: 0.0030 - mean_absolute_error: 0.0112 - categorical_accuracy: 0.5834 - binary_accuracy: 0.9929 - exact_match_accuracy: 0.0000e+00\n",
      "Epoch 2/5\n",
      "19123/19123 [==============================] - 115s 6ms/step - loss: 0.0028 - mean_absolute_error: 0.0104 - categorical_accuracy: 0.6045 - binary_accuracy: 0.9934 - exact_match_accuracy: 0.0000e+00 2s - loss: 0.0028 - mean_absolute_error: 0.0104 - categorical_accuracy: 0.6044 - binary_accuracy: 0.9934 - exact_match_accurac\n",
      "Epoch 3/5\n",
      "19123/19123 [==============================] - 112s 6ms/step - loss: 0.0027 - mean_absolute_error: 0.0097 - categorical_accuracy: 0.6277 - binary_accuracy: 0.9938 - exact_match_accuracy: 3.1376e-04\n",
      "Epoch 4/5\n",
      "19123/19123 [==============================] - 114s 6ms/step - loss: 0.0026 - mean_absolute_error: 0.0097 - categorical_accuracy: 0.6328 - binary_accuracy: 0.9940 - exact_match_accuracy: 1.0459e-04\n",
      "Epoch 5/5\n",
      "19123/19123 [==============================] - 115s 6ms/step - loss: 0.0026 - mean_absolute_error: 0.0094 - categorical_accuracy: 0.6405 - binary_accuracy: 0.9941 - exact_match_accuracy: 2.6147e-04\n",
      "89-D8     89-D8     85-F2D   False\n",
      "81-32     81-32     85-F2D   False\n",
      "MM88-15   MM88-15   SH88-10  False\n",
      "93J-397   93J-397   P8B-10   False\n",
      "93-EDH    93-EDH    90-GDD   False\n",
      "D88-6     D88-6     P8B-10   False\n",
      "92-DMK    92-DMK    90-GDD   False\n",
      "84-ER08   84-ER08   84-T3    False\n",
      "80H-95    80H-95    88B-10   False\n",
      "85-XNW    85-XNW    85-F1D   False\n",
      "S78-2     S78-2     P8B-10   False\n",
      "T83FC-8   T83FC-8   SH88-10  False\n",
      "82-QPW    82-QPW    85-F2D   False\n",
      "85-XSK    85-XSK    85-F1D   False\n",
      "CR95A-11  CR95A-11  P89--12  False\n",
      "85-YCH    85-YCH    85-F2D   False\n",
      "MM88-7    MM88-7    SH88-10  False\n",
      "AT92-10   AT92-10   S888-11  False\n",
      "AD91-27   AD91-27   S888-10  False\n",
      "93J-482   93J-482   P89--02  False\n",
      "82-LFQ    82-LFQ    85-F2D   False\n",
      "94-EXE    94-EXE    90-GDD   False\n",
      "94-EXF    94-EXF    90-GDD   False\n",
      "\n",
      "4780/4780 [==============================] - 9s 2ms/step\n",
      "('mean_squared_logarithmic_error', 0.0027103656195649668)\n",
      "('mean_absolute_error', 0.009604004407340513)\n",
      "('categorical_accuracy', 0.6138249648664785)\n",
      "('binary_accuracy', 0.9939432313252693)\n",
      "(<function exact_match_accuracy at 0x000002266C54BE18>, 0.0)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "epochs = 5\n",
    "batch_size = 32\n",
    "model = models['GRU-RNN2']\n",
    "\n",
    "model.fit(train_x, train_y, batch_size=batch_size, epochs=epochs)\n",
    "l, a = test()\n",
    "training_log(x_name, y_name, architecture, batch_size, epochs, l, a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'x': 'LineName', 'y': 'LineName', 'architecture': 'GRU-RNN1', 'batch size': 64, 'epochs': 1, 'loss': 0.0019871394849425203, 'accuracy': 0.0020920502092050207}\n",
      "{'x': 'LineName', 'y': 'LineName', 'architecture': 'GRU-RNN1', 'batch size': 64, 'epochs': 1, 'loss': 0.001942680378456183, 'accuracy': 0.0031380753138075313}\n",
      "{'x': 'LineName', 'y': 'LineName', 'architecture': 'GRU-RNN1', 'batch size': 32, 'epochs': 1, 'loss': 0.0019508493095870172, 'accuracy': 0.0016736401673640166}\n",
      "{'x': 'LineName', 'y': 'LineName', 'architecture': 'GRU-RNN1', 'batch size': 32, 'epochs': 0, 'loss': 0.0019508493095870172, 'accuracy': 0.0016736401673640166}\n",
      "{'x': 'LineName', 'y': 'LineName', 'architecture': 'P-NN', 'batch size': 32, 'epochs': 0, 'loss': 0.4744374025067525, 'accuracy': 0.0}\n",
      "{'x': 'LineName', 'y': 'LineName', 'architecture': 'P-NN', 'batch size': 32, 'epochs': 25, 'loss': 0.00017522789327725847, 'accuracy': 0.9205020921000876}\n",
      "{'x': 'LineName', 'y': 'LineName', 'architecture': 'P-NN', 'batch size': 32, 'epochs': 0, 'loss': 0.00023692987049943437, 'accuracy': 0.8531380752639292}\n",
      "{'x': 'LineName', 'y': 'LineName', 'architecture': 'P-NN', 'batch size': 32, 'epochs': 0, 'loss': 0.0019508493095870172, 'accuracy': 0.0016736401673640166}\n",
      "{'x': 'LineName', 'y': 'LineName', 'architecture': 'GRU-RNN2', 'batch size': 32, 'epochs': 1, 'loss': 0.0031901488390412166, 'accuracy': 0.0}\n",
      "{'x': 'LineName', 'y': 'LineName', 'architecture': 'GRU-RNN2', 'batch size': 32, 'epochs': 5, 'loss': 0.0027103656195649668, 'accuracy': 0.0}\n"
     ]
    }
   ],
   "source": [
    "print(*training_history[-10:], sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
